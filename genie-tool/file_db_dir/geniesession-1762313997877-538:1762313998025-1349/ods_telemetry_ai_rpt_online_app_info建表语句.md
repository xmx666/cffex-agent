# CREATE TABLE 语句与字段注释说明

## 表结构定义

```sql
CREATE TABLE ods_telemetry.ai_rpt_online_app_info (
    service_showname VARCHAR(255) NOT NULL COMMENT '服务在报表或监控系统中对外展示的名称，通常为用户可见的业务服务标识，用于区分不同应用或微服务的可视化呈现，可能包含业务线、产品模块或功能组的语义化命名',
    service_system VARCHAR(255) NOT NULL COMMENT '服务所属的系统或平台名称，用于标识该服务所归属的高层级技术架构或业务系统，如“订单中心”、“用户中台”、“支付网关”等，用于系统级归类与权限隔离',
    network_region VARCHAR(255) NOT NULL COMMENT '服务部署或运行所处的网络区域，用于标识服务实例的物理或逻辑网络位置，如“华北-北京”、“华南-深圳”、“海外-新加坡”、“VPC-internal”、“DMZ-外网”等，支持跨区域流量分析与合规性审计',
    7d_sql TEXT NOT NULL COMMENT '近7日聚合的SQL查询语句，为基于过去7天内所有相关数据库请求生成的标准化、去参数化后的代表性SQL模板，用于性能分析、慢查询识别与索引优化，语句中参数值已被占位符（如?或:1）替代，保留结构与逻辑',
    last_7d_sql TEXT NOT NULL COMMENT '上一个7日周期（即前8至14天）的聚合SQL查询语句，与7d_sql形成时间对比基准，用于分析SQL执行模式的周期性变化、趋势偏离或异常波动，支持同比分析与基线比对',
    7day_by_day_sql TEXT NOT NULL COMMENT '近7日每日逐条记录的SQL查询语句集合，以结构化文本形式存储每日的SQL执行日志，每条记录按时间顺序排列，可能包含多个SQL语句，用于细粒度的每日波动分析、异常定位与回溯审计',
    last_7day_by_day_sql TEXT NOT NULL COMMENT '上一个7日周期（前8至14天）每日逐条记录的SQL查询语句集合，与7day_by_day_sql构成时间序列对比数据，支持逐日趋势对比、异常模式复现与周期性行为建模'
) COMMENT '在线应用服务SQL性能监控基础表，用于存储服务维度的SQL执行历史数据，支撑自动化性能分析、异常检测、资源优化与容量规划，数据来源于数据库审计日志、APM探针采集与SQL日志聚合系统';
```

## 字段详细说明与背景扩展

### service_showname：服务展示名称

`service_showname` 字段用于在报表、仪表盘、告警系统或运维平台中向终端用户、运维人员或业务负责人展示服务的可读性名称。该字段不直接对应系统内部的服务ID或代码包名，而是经过语义化处理后的业务友好标识。例如，一个内部微服务名为 `order-service-v2`，其 `service_showname` 可能被设置为“订单服务-2.0版”或“电商-订单创建模块”，以便非技术人员快速识别其业务含义。

在实际运维场景中，`service_showname` 常用于构建服务拓扑图、生成性能看板、配置告警规则和生成日报摘要。由于其面向展示，该字段通常由运维团队或DevOps平台在服务注册时手动或半自动配置，也可能从配置中心（如Nacos、Consul）或CI/CD流水线中同步获取。不同团队可能对同一服务使用不同的展示名称，导致数据存在语义冗余或歧义，因此在数据治理层面，建议建立 `service_showname` 与 `service_system`、`service_id` 的映射关系表，以实现标准化管理。

该字段的值通常为中文或中英文混合，长度限制为255字符，足以容纳大多数业务命名规范。例如：“用户中心-登录认证模块”、“支付网关-微信支付通道”、“推荐引擎-实时推荐服务”等。在某些企业中，`service_showname` 会包含版本号、环境标识（如prod、pre）或所属BU（如“零售BU-购物车服务”），以增强可追溯性。

在数据聚合分析中，`service_showname` 是最常用于分组聚合的维度之一。例如，在生成“Top 10 慢服务”报表时，系统通常按 `service_showname` 分组，统计其对应的SQL执行耗时、调用量、错误率等指标。由于其非唯一性（可能存在多个实例共享同一展示名），在进行精确服务追踪时，需结合 `service_system` 和 `network_region` 进行联合去重。

该字段的命名规范在不同组织中存在差异。部分企业采用“业务域-功能模块”结构（如“风控-反欺诈引擎”），部分采用“产品线-服务类型”结构（如“直播-弹幕服务”），还有部分企业使用“系统简称-功能缩写”（如“UC-Auth”）。这些差异反映了组织内部的治理成熟度，也影响了跨团队数据整合的难度。

在数据质量监控中，`service_showname` 的缺失或异常值（如空字符串、纯数字、乱码）常被作为数据采集异常的预警信号。例如，若某服务的 `service_showname` 为 `null` 或 `UNKNOWN`，则可能表明该服务未在服务注册中心正确注册，或日志采集代理未正确配置元数据注入逻辑。

### service_system：服务所属系统

`service_system` 字段用于标识服务所归属的高层级技术系统或业务平台，是服务治理中的关键分类维度。该字段通常对应企业内部的“系统清单”或“IT资产目录”，其值由架构团队或平台团队统一维护，具有较强的权威性和稳定性。例如，一个微服务可能属于“用户中台”、“订单中心”、“风控引擎”、“数据仓库”或“营销自动化平台”等系统。

该字段的核心价值在于实现服务的系统级归类与资源隔离。在大型企业中，一个系统可能包含数十甚至上百个微服务，而 `service_system` 使得运维人员能够快速定位服务所属的业务域，从而判断其重要性、SLA等级、变更审批流程和故障响应优先级。例如，属于“支付网关”的服务通常被定义为P0级核心系统，而“活动页面展示服务”可能为P2级。

在数据仓库建模中，`service_system` 常作为维度表（Dimension Table）的主键或外键，用于构建服务-系统-业务线的多维分析模型。例如，在分析“各系统SQL执行总量趋势”时，可按 `service_system` 分组，绘制柱状图或热力图，识别出SQL负载最高的系统，进而推动系统级优化项目。

该字段的取值通常为中文命名，且具有一定的层级结构。例如：“用户中台”下可能包含“用户登录”、“用户画像”、“权限管理”等多个服务；“数据中台”下可能包含“数据采集”、“数据清洗”、“BI报表”等服务。部分企业采用“系统-子系统”二级结构，如“支付系统-微信支付”、“支付系统-支付宝支付”，以支持更细粒度的管理。

在数据治理实践中，`service_system` 的标准化是数据质量提升的关键一步。若该字段存在大量同义词（如“用户中心”、“用户平台”、“User Platform”）、缩写不一致（如“UC” vs “用户中台”）或拼写错误（如“订单中台”误写为“订单中心”），将严重影响跨系统分析的准确性。因此，建议建立《服务系统命名规范白皮书》，并由数据治理委员会定期审核和更新。

在监控告警体系中，`service_system` 常用于配置告警策略的分组规则。例如，可为“支付系统”设置更严格的告警阈值和更快速的响应流程，而为“内部工具系统”设置较低的告警级别。此外，在故障演练（Chaos Engineering）中，`service_system` 用于定义影响范围，确保演练仅影响非核心系统。

该字段的值通常来源于服务注册中心、配置管理数据库（CMDB）或自动化部署平台（如Jenkins、ArgoCD）的元数据注入。在Kubernetes环境中，该字段可能由Deployment的Label（如 `system=payment-gateway`）自动提取并写入日志采集器。

### network_region：网络区域

`network_region` 字段用于标识服务实例所部署或运行的网络区域，是实现地理分布、网络隔离、合规性审计和流量调度的关键维度。该字段的取值通常反映物理数据中心、云区域、VPC、安全域或网络边界，如“华北-北京”、“华南-深圳”、“华东-上海”、“海外-新加坡”、“VPC-internal”、“DMZ-外网”、“专有云-金融区”等。

在分布式系统架构中，服务可能在多个网络区域部署多个实例，以实现高可用、低延迟或数据主权合规。例如，一家跨国电商企业可能在“华北-北京”部署面向中国用户的订单服务，在“海外-新加坡”部署面向东南亚用户的同名服务。`network_region` 使得运维团队能够区分不同区域的性能表现、网络延迟、故障影响范围和合规风险。

该字段在性能分析中具有重要价值。例如，若某服务在“海外-新加坡”区域的SQL执行耗时显著高于“华北-北京”，则可能表明该区域的数据库实例存在资源瓶颈、网络链路拥塞或DNS解析异常。在进行跨区域对比分析时，`network_region` 是必须的分组维度。

在合规性审计中，`network_region` 是数据主权和隐私保护的核心依据。例如，根据《个人信息保护法》和《数据安全法》，中国境内用户的数据必须存储于中国境内服务器。若某服务的 `network_region` 为“海外-新加坡”，但其处理的是中国用户的身份信息，则可能触发合规风险告警。因此，该字段常与用户IP归属、数据分类标签（如“个人敏感信息”）联动，用于自动化合规检查。

网络区域的命名规范在不同企业中存在较大差异。部分企业采用“大区-城市”结构（如“华东-上海”），部分采用“云厂商区域”命名（如“cn-hangzhou”、“ap-southeast-1”），部分采用“安全域”命名（如“生产区-核心”、“测试区-隔离”）。在混合云环境中，`network_region` 可能包含云厂商标识，如“AWS-ap-southeast-1”、“阿里云-cn-shanghai”。

在数据采集层面，`network_region` 通常由基础设施层自动注入。在Kubernetes中，可通过Node Label（如 `topology.kubernetes.io/region=cn-hangzhou`）获取；在虚拟机环境中，可通过主机元数据服务（如AWS EC2 Metadata）或配置文件注入；在容器平台中，可能由CI/CD流水线在部署时动态设置。

该字段的缺失或错误可能导致严重的分析偏差。例如，若某服务的 `network_region` 被错误标记为“华北-北京”，而实际部署在“华南-深圳”，则其性能数据将被错误归入华北区域，导致容量规划失真。因此，建议建立 `network_region` 与物理/云资源ID的映射关系，并通过自动化巡检工具定期校验。

在多租户架构中，`network_region` 还可用于实现租户隔离。例如，金融客户的数据服务部署在“专有云-金融区”，而普通客户的服务部署在“公有云-通用区”，两者网络策略、访问控制和审计日志完全隔离。

### 7d_sql：近7日SQL查询语句

`7d_sql` 字段存储的是过去7天内所有数据库查询请求经过聚合、去参数化和标准化后的代表性SQL模板。该字段的核心价值在于将海量的原始SQL日志压缩为具有代表性的查询模式，从而支持高效的性能分析、慢查询识别与索引优化。

在数据库运维中，原始SQL日志通常包含大量参数化查询，如 `SELECT * FROM users WHERE id = 12345` 和 `SELECT * FROM users WHERE id = 67890`，这些查询在逻辑上完全相同，仅参数不同。`7d_sql` 通过将参数替换为占位符（如 `?`、`:1` 或 `$1`），生成标准化模板：`SELECT * FROM users WHERE id = ?`。这种处理方式显著降低了数据冗余，使分析系统能够识别出高频执行的SQL模式，而非被海量参数变体淹没。

该字段的生成过程通常由数据库审计代理、APM探针（如SkyWalking、Pinpoint）或日志聚合平台（如ELK、Splunk）完成。其算法包括：SQL语法解析、AST（抽象语法树）标准化、常量替换、空格与换行归一化、大小写统一、别名重命名等。例如，`SELECT name AS n FROM user_table WHERE age > 18` 和 `select name as n from user_table where age > 18` 会被统一为 `SELECT name AS n FROM user_table WHERE age > ?`。

`7d_sql` 的内容通常为文本格式，长度限制为TEXT类型，足以容纳复杂的多表JOIN、子查询、窗口函数等结构。例如：

```sql
SELECT o.order_id, u.username, p.product_name, o.amount 
FROM orders o 
JOIN users u ON o.user_id = u.id 
JOIN products p ON o.product_id = p.id 
WHERE o.status = ? AND o.created_at >= ? 
ORDER BY o.created_at DESC 
LIMIT ?
```

该字段是数据库性能优化的核心输入。DBA和SRE团队通过分析 `7d_sql` 的执行频率、平均耗时、扫描行数、锁等待时间等指标，识别出“Top N 慢SQL”和“高频低效查询”。例如，若某条SQL在7天内执行了100万次，平均耗时500ms，则即使单次耗时不高，其累积资源消耗也极为可观，应优先优化。

在索引建议生成中，`7d_sql` 是关键输入。许多数据库优化工具（如MySQL的 `EXPLAIN` 分析器、PostgreSQL的 `pg_stat_statements`）会基于标准化SQL模板推荐索引。例如，若某SQL频繁使用 `WHERE status = ? AND created_at >= ?`，系统可建议创建复合索引 `(status, created_at)`。

该字段的准确性高度依赖于SQL解析器的质量。若解析器无法正确识别子查询、CTE（公共表表达式）或复杂函数，可能导致模板错误，进而误导优化决策。例如，将 `WHERE DATE(created_at) = '2025-11-01'` 错误标准化为 `WHERE ? = ?`，将丢失时间范围的关键语义。

在数据治理层面，`7d_sql` 可能包含敏感信息（如身份证号、手机号），即使参数已被替换，SQL结构本身仍可能暴露业务逻辑。例如，`SELECT * FROM users WHERE id IN (SELECT user_id FROM blacklist)` 可能暗示存在黑名单机制，存在信息泄露风险。因此，在数据脱敏流程中，需对 `7d_sql` 进行额外的语义脱敏处理。

### last_7d_sql：上一个7日周期SQL查询语句

`last_7d_sql` 字段存储的是前一个7日周期（即当前周期的前8至14天）内聚合生成的标准化SQL模板，与 `7d_sql` 构成时间对比基准，用于实现同比分析（YoY）和趋势偏离检测。

该字段的核心价值在于提供“历史基线”，使分析系统能够识别SQL执行模式的异常变化。例如，若 `7d_sql` 中某条SQL的执行频率从上周的10万次骤增至本周的50万次，则可能表明存在业务高峰、爬虫攻击、缓存失效或代码发布引入的性能问题。反之，若某条SQL本周消失，而上周仍高频出现，则可能意味着功能下线、缓存生效或服务降级。

在自动化根因分析（RCA）系统中，`last_7d_sql` 与 `7d_sql` 的差异分析是核心算法之一。系统会计算两组SQL集合的Jaccard相似度、执行频率变化率、平均耗时增长率等指标，自动标记“显著变化SQL”并生成告警。例如：

- **频率突增**：`7d_sql` 中某SQL执行次数 > `last_7d_sql` 中的200%，且绝对值 > 1000次/天 → 触发“SQL流量异常”告警
- **耗时突增**：`7d_sql` 中某SQL平均耗时 > `last_7d_sql` 中的300% → 触发“性能退化”告警
- **SQL消失**：`last_7d_sql` 中存在但 `7d_sql` 中缺失的SQL，且上周执行次数 > 5000次 → 触发“功能异常”告警

该字段的生成逻辑与 `7d_sql` 完全一致，仅时间窗口不同。其数据来源、标准化规则、参数替换方式均与 `7d_sql` 保持同步，确保对比的公平性与有效性。

在容量规划中，`last_7d_sql` 用于预测未来负载。例如，若过去两周的SQL总量呈线性增长（每周+15%），则可预测下一周将增长约30%，从而提前扩容数据库实例或调整连接池配置。

在变更管理中，`last_7d_sql` 是发布后验证的关键依据。在新版本上线后，运维团队会对比上线前后的 `7d_sql` 与 `last_7d_sql`，确认是否存在新引入的慢查询、重复查询或全表扫描。若发现新SQL模式与历史基线差异显著，则可能触发回滚流程。

该字段的缺失或延迟将导致分析系统失效。例如，若 `last_7d_sql` 数据因采集故障未更新，则系统无法判断当前SQL是否异常，所有告警将失去基准。因此，建议为 `last_7d_sql` 设置独立的采集通道和数据校验机制。

在数据可视化中，`7d_sql` 与 `last_7d_sql` 常被并列展示于性能看板，形成“双时间线”对比图。例如，使用折线图展示“近7日 vs 上7日”各服务的SQL执行总量趋势，或使用热力图展示SQL执行频率的变化强度（红色为激增，蓝色为下降）。

### 7day_by_day_sql：近7日每日逐条SQL记录

`7day_by_day_sql` 字段存储的是近7天内每日逐条记录的原始SQL查询语句集合，其数据粒度远细于 `7d_sql`，支持对每日SQL执行行为进行微观分析与异常回溯。

该字段的内容通常为JSON数组、换行分隔的文本串或结构化日志格式，每条记录代表一个数据库请求，包含完整的SQL语句（含参数）、执行时间戳、执行耗时、客户端IP、用户ID等元信息。例如：

```json
[
  {
    "sql": "SELECT * FROM users WHERE id = 12345",
    "exec_time": "2025-10-29T08:15:23Z",
    "duration_ms": 45,
    "client_ip": "192.168.1.100",
    "user_id": "u_98765"
  },
  {
    "sql": "UPDATE orders SET status = 'paid' WHERE order_id = 67890",
    "exec_time": "2025-10-29T08:15:24Z",
    "duration_ms": 120,
    "client_ip": "192.168.1.101",
    "user_id": "u_98766"
  }
]
```

该字段的核心价值在于支持**细粒度异常定位**。例如，若某服务在某日14:00-15:00出现性能抖动，可通过 `7day_by_day_sql` 精确回溯该时间段内的所有SQL执行记录，识别出是否存在突发的慢查询、死锁、全表扫描或高频重复查询。

在故障复盘（Postmortem）中，`7day_by_day_sql` 是不可或缺的证据链。当发生线上事故时，运维团队可按时间戳精确还原数据库操作序列，判断是代码缺陷、数据异常、外部依赖故障还是人为误操作导致问题。

该字段的数据量远大于 `7d_sql`，因此通常采用压缩存储或分片存储策略。例如，每日数据单独存储为一个JSON文件，或按小时分片写入Kafka主题，再由下游流处理引擎（如Flink）聚合后写入本表。由于其为TEXT类型，可容纳数万条记录，但需注意存储成本与查询性能的平衡。

在数据治理层面，`7day_by_day_sql` 包含大量敏感信息（如用户ID、订单号、金额），因此必须实施严格的访问控制和脱敏策略。在非生产环境中，应使用数据脱敏工具（如Apache Griffin、Delphix）对参数值进行掩码处理（如 `id=12345` → `id=****`）。

该字段的分析方法包括：
- **时间序列聚类**：识别每日SQL模式的周期性（如工作日 vs 周末）
- **异常检测**：使用Isolation Forest、LOF等算法识别偏离正常模式的SQL
- **关联分析**：分析SQL执行与应用日志、监控指标（CPU、内存）的时序关联

例如，若某日14:00出现大量 `SELECT * FROM inventory WHERE stock < 10`，同时应用服务器CPU飙升，可推断为库存查询未缓存导致数据库压力激增。

### last_7day_by_day_sql：上一个7日周期每日逐条SQL记录

`last_7day_by_day_sql` 字段存储的是前一个7日周期（前8至14天）内每日逐条记录的原始SQL查询语句集合，与 `7day_by_day_sql` 构成完整的14天时间序列，支持深度趋势分析、周期性行为建模与异常模式复现。

该字段的核心价值在于提供**历史上下文**，使分析系统能够识别“是否为偶发事件”或“是否为周期性模式”。例如，若某服务在本周三14:00出现SQL峰值，而上周三同一时间也出现相同峰值，则可判断为业务周期性行为（如每日定时任务），无需告警；若仅本周出现，则可能为异常事件。

在自动化根因分析中，`last_7day_by_day_sql` 与 `7day_by_day_sql` 的逐日对比是核心算法。系统可计算每日SQL执行总量、平均耗时、慢查询数量、异常SQL出现频次等指标，生成“每日变化曲线”，并标记显著偏离历史模式的日期。

例如：
- **周期性确认**：若过去两周每周一上午9:00均出现SQL高峰，则系统可自动标记为“正常业务高峰”，不触发告警
- **异常模式识别**：若本周五15:00出现1000次 `DELETE FROM logs WHERE created_at < '2025-10-01'`，而上周五无此操作，则触发“异常删除操作”告警
- **模式复现**：若本周某条慢SQL的执行序列与上周某次故障日志完全一致，则可自动关联历史事故，建议复用解决方案

该字段在容量预测中具有重要价值。通过分析过去两周的每日SQL负载曲线，可建立时间序列预测模型（如ARIMA、Prophet），预测未来7天的数据库负载，从而实现动态扩缩容。

在数据安全审计中，`last_7day_by_day_sql` 可用于检测“历史异常行为是否重现”。例如，若上月曾发生一次SQL注入攻击（表现为大量 `OR '1'='1'` 模式），则系统可监控本周是否再次出现相同模式，实现主动防御。

该字段的存储与处理挑战与 `7day_by_day_sql` 相同，需考虑存储成本、查询效率与数据脱敏。由于其数据量更大（14天），建议采用冷热分层存储策略：最近7天数据存于热存储（如Elasticsearch），前7天数据存于冷存储（如HDFS、S3），按需加载。

在数据可视化中，`7day_by_day_sql` 与 `last_7day_by_day_sql` 可组合为“双周热力图”，横轴为日期（14天），纵轴为SQL类型，颜色表示执行频率，直观展示模式变化。

## 表整体设计逻辑与数据流分析

### 表设计目标与业务价值

`ods_telemetry.ai_rpt_online_app_info` 表的设计目标是构建一个**面向AI驱动的在线应用性能监控与优化的标准化数据源**，其核心价值体现在以下四个方面：

1. **性能瓶颈识别**：通过 `7d_sql` 与 `last_7d_sql` 的对比，自动识别高频、高耗时、低效SQL，为DBA提供优化优先级排序。
2. **异常行为检测**：通过 `7day_by_day_sql` 与 `last_7day_by_day_sql` 的逐日对比，发现突发性、周期性或异常模式的SQL行为，支持自动化告警与根因分析。
3. **系统级归因分析**：通过 `service_showname`、`service_system`、`network_region` 三维度交叉分析，定位性能问题的业务域、技术系统与部署区域，实现精准定位。
4. **容量规划与资源调度**：基于历史SQL负载趋势，预测未来数据库资源需求，支持自动扩缩容、连接池调整与索引预建。

该表是企业级可观测性（Observability）体系中的关键数据资产，其数据来源于数据库审计日志、APM探针、SQL代理、日志采集器（如Fluentd、Logstash）等，经过清洗、标准化、聚合后写入本表，供BI系统、AI分析平台、自动化运维系统调用。

### 数据采集与处理流程

该表的数据采集流程通常遵循以下步骤：

1. **源头采集**：数据库（MySQL、PostgreSQL、Oracle）开启审计日志，或通过代理（如ProxySQL、MaxScale）捕获SQL请求；应用端通过APM探针（如SkyWalking、Pinpoint）采集SQL执行信息。
2. **原始日志**：采集到的原始数据包含完整SQL语句、参数、执行时间、客户端信息、用户ID、耗时、返回行数等。
3. **参数脱敏与标准化**：通过SQL解析器将参数替换为占位符，生成标准化SQL模板（用于 `7d_sql` 和 `last_7d_sql`）；对敏感参数（如身份证、手机号）进行脱敏处理。
4. **聚合计算**：按 `service_showname`、`service_system`、`network_region` 分组，聚合过去7天和前7天的SQL模板，生成 `7d_sql` 和 `last_7d_sql`。
5. **逐日存储**：按天分片，将每日的原始SQL记录（含参数）按时间顺序拼接为文本串，存入 `7day_by_day_sql` 和 `last_7day_by_day_sql`。
6. **元数据注入**：从服务注册中心、CMDB、Kubernetes等系统获取 `service_showname`、`service_system`、`network_region`，注入到每条记录。
7. **写入目标表**：通过ETL工具（如DataX、Sqoop）或流处理引擎（如Flink）将聚合结果与原始记录写入 `ods_telemetry.ai_rpt_online_app_info` 表。

该流程通常每日凌晨执行一次全量更新，或采用流式写入（每小时增量更新），以保证数据时效性。

### 数据使用场景与典型分析案例

#### 场景一：慢SQL自动优化推荐

**问题**：某电商系统在促销期间出现订单创建延迟。

**分析过程**：
- 查询 `7d_sql`，发现 `UPDATE orders SET status = 'paid' WHERE order_id = ?` 执行频率为 800,000 次/天，平均耗时 420ms。
- 对比 `last_7d_sql`，发现上周该SQL平均耗时为 85ms。
- 查看 `7day_by_day_sql`，发现本周三14:00后该SQL耗时突增，且伴随大量 `SELECT * FROM inventory WHERE product_id = ?`。
- 分析发现，订单服务在支付成功后未使用缓存，直接查询库存表，导致数据库锁竞争加剧。
- **结论**：建议为 `inventory` 表添加 `(product_id)` 索引，并引入Redis缓存库存信息。

#### 场景二：异常SQL行为告警

**问题**：某金融系统出现大量删除操作。

**分析过程**：
- `7day_by_day_sql` 中发现某日出现 12,000 次 `DELETE FROM transaction_logs WHERE created_at < '2025-10-01'`。
- `last_7day_by_day_sql` 中无此模式。
- `service_showname` 为“风控-日志清理服务”，`service_system` 为“风控引擎”。
- 调查发现，该服务为临时脚本，非正式发布流程，存在误删风险。
- **结论**：触发“非授权SQL执行”告警，冻结该服务权限，启动变更审计流程。

#### 场景三：跨区域性能对比

**问题**：海外用户反馈应用响应慢。

**分析过程**：
- 按 `network_region` 分组，发现“海外-新加坡”区域的 `7d_sql` 平均耗时为 680ms，而“华北-北京”为 120ms。
- 查看 `7day_by_day_sql`，发现新加坡区域存在大量 `SELECT * FROM user_profiles WHERE country = 'SG'`，且无索引。
- `last_7d_sql` 显示该SQL上周耗时为 150ms，本周突增。
- 调查发现，新上线的推荐模块未为新加坡用户建立分区索引。
- **结论**：建议为 `user_profiles` 表添加 `(country)` 索引，并部署区域专用数据库副本。

### 数据质量与治理建议

为保障该表的数据可用性与分析准确性，建议实施以下治理措施：

| 治理维度 | 建议措施 |
|----------|----------|
| **完整性** | 设置数据采集监控，若连续2小时无新数据，触发告警；确保 `service_showname`、`service_system`、`network_region` 不为空 |
| **一致性** | 建立《服务命名规范》与《网络区域命名标准》，由数据治理委员会审核；使用字典表（Dictionary Table）约束取值 |
| **准确性** | 定期抽样校验 `7d_sql` 与原始日志的标准化一致性；使用SQL解析器版本管理，避免因解析器升级导致模板变化 |
| **安全性** | 对 `7day_by_day_sql` 和 `last_7day_by_day_sql` 中的参数进行脱敏（如手机号→138****1234）；实施基于RBAC的访问控制 |
| **时效性** | 采用流式处理（Flink）实现近实时更新，延迟控制在15分钟内；设置数据延迟告警（>1小时） |
| **存储优化** | 对 `7day_by_day_sql` 和 `last_7day_by_day_sql` 使用压缩格式（如GZIP）；冷热分层存储，历史数据归档至对象存储 |
| **元数据管理** | 建立该表的血缘关系图，标注数据来源、处理逻辑、责任人；与CMDB、服务注册中心联动，实现自动同步 |

### 与其他数据表的关联关系

该表通常作为数据仓库中的**操作数据存储层（ODS）**，其下游会连接多个分析层表：

- **DWD层（明细宽表）**：`dwd_telemetry.sql_performance_detail`，扩展字段如 `sql_hash`、`execution_plan`、`index_used`、`lock_wait_time`
- **DWS层（汇总宽表）**：`dws_telemetry.sql_summary_daily`，按天聚合 `service_system`、`network_region`、`sql_type`（SELECT/UPDATE/DELETE）的执行次数、耗时、错误率
- **ADS层（应用层）**：`ads_rpt.top_slow_sql_weekly`，Top 10慢SQL报表；`ads_rpt.region_performance_trend`，区域性能趋势图
- **AI模型输入表**：`ml_input.sql_anomaly_features`，用于训练异常检测模型，特征包括：SQL频率变化率、耗时标准差、并发连接数、CPU负载相关性等

该表与 `service_catalog`（服务目录）、`cmdb_system`（系统资产）、`network_topology`（网络拓扑）等元数据表建立外键关联，实现端到端的可观测性闭环。

### 技术实现建议与工具推荐

| 功能 | 推荐工具 | 说明 |
|------|----------|------|
| **SQL解析与标准化** | Apache Calcite、JSqlParser、SQLFluff | 支持多数据库语法解析，可自定义标准化规则 |
| **日志采集** | Fluentd、Logstash、Vector | 支持从数据库日志、应用日志、Kubernetes容器日志中采集 |
| **流式处理** | Apache Flink、Spark Streaming | 实现实时聚合与异常检测 |
| **存储引擎** | MySQL、PostgreSQL、ClickHouse | ClickHouse适合高吞吐写入与聚合查询 |
| **数据脱敏** | Apache Griffin、Delphix、Talend Data Quality | 支持正则匹配、掩码、哈希脱敏 |
| **可视化分析** | Grafana、Superset、Tableau | 支持多维度钻取、时间序列对比、热力图 |
| **自动化告警** | Prometheus + Alertmanager、Datadog、Zabbix | 基于SQL频率、耗时、错误率设置动态阈值 |
| **AI分析** | Python + Scikit-learn、PyTorch | 用于训练SQL异常检测模型、趋势预测模型 |

### 潜在风险与应对策略

| 风险 | 描述 | 应对策略 |
|------|------|----------|
| **数据泄露** | `7day_by_day_sql` 包含敏感参数 | 实施字段级脱敏，访问控制，审计日志 |
| **存储爆炸** | 每日数百万条SQL记录 | 采用压缩、分片、冷热分离、TTL自动清理 |
| **解析错误** | SQL语法复杂导致标准化失败 | 使用成熟解析器，定期校验，人工复核 |
| **元数据不一致** | `service_showname` 与实际服务不符 | 建立自动化同步机制，与CMDB联动 |
| **分析偏差** | 未区分读写SQL，导致优化方向错误 | 在标准化时标记SQL类型（SELECT/UPDATE/DELETE） |
| **依赖单点** | 依赖单一采集代理 | 部署多采集通道，主备切换，数据校验 |

### 未来扩展方向

1. **SQL指纹生成**：为每条标准化SQL生成唯一哈希（如SHA-256），用于快速去重与关联分析。
2. **执行计划存储**：扩展字段存储 `execution_plan`，用于分析索引使用情况与查询优化器行为。
3. **用户行为关联**：关联用户ID与SQL执行，识别异常用户行为（如爬虫、恶意刷库）。
4. **自动优化建议**：基于AI模型自动生成索引建议、SQL重写建议、缓存策略建议。
5. **多租户支持**：扩展 `tenant_id` 字段，支持SaaS平台的租户级性能隔离分析。
6. **实时流式分析**：将本表升级为实时流表，支持毫秒级SQL异常检测。

## 总结

`ods_telemetry.ai_rpt_online_app_info` 表是一个结构严谨、语义清晰、用途明确的数据库性能监控基础表。其七个字段从**服务标识**（`service_showname`、`service_system`、`network_region`）到**SQL行为**（`7d_sql`、`last_7d_sql`、`7day_by_day_sql`、`last_7day_by_day_sql`）构建了完整的分析维度，覆盖了从宏观系统归类到微观执行细节的全链路观测需求。

该表的设计充分体现了“**分层聚合、对比分析、细粒度回溯**”的现代可观测性理念，是支撑自动化运维、智能优化与数据驱动决策的核心数据资产。其成功应用依赖于高质量的数据采集、标准化处理与严格的治理机制。在大型互联网企业或金融系统中，该表的建设与维护已成为DevOps与数据工程团队的标配能力。

通过该表，企业可实现从“被动响应故障”到“主动预测优化”的转变，显著提升系统稳定性、资源利用率与用户体验。