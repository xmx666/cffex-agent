Html:
```html
<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI模型调用性能与资源优化建议报告（2025年12月）</title>
  <link rel="stylesheet" href="/static-resources/font-awesome/all.min.css" />
  <link rel="stylesheet" href="/static-resources/tailwindcss/tailwind.min.css" />
  <link href="/static-resources/googleapis-fonts/css2.css" rel="stylesheet" />
  <style>
    @import url('/static-resources/googleapis-fonts/css2.css');
    body {
      font-family: 'Noto Sans SC', 'Segoe UI', sans-serif;
      background-color: #f8fafc;
      color: #1e293b;
    }
    .card {
      box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
      border-radius: 0.5rem;
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    .card:hover {
      transform: translateY(-2px);
      box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
    }
    .section-title {
      border-bottom: 2px solid #e2e8f0;
      padding-bottom: 0.5rem;
      margin-bottom: 1.5rem;
      color: #1e293b;
    }
    .data-point {
      font-weight: 600;
      color: #0f172a;
    }
    .highlight {
      background-color: #f1f5f9;
      padding: 0.25rem 0.5rem;
      border-radius: 0.25rem;
      font-size: 0.875rem;
    }
    .badge {
      font-size: 0.75rem;
      padding: 0.25rem 0.5rem;
      border-radius: 9999px;
    }
    .badge-success {
      background-color: #d1fae5;
      color: #065f46;
    }
    .badge-warning {
      background-color: #fef3c7;
      color: #92400e;
    }
    .badge-danger {
      background-color: #fee2e2;
      color: #b91c1c;
    }
    .table-responsive {
      overflow-x: auto;
    }
    .chart-container {
      height: 300px;
      margin: 1rem 0;
    }
    .tooltip {
      position: relative;
      display: inline-block;
    }
    .tooltip .tooltiptext {
      visibility: hidden;
      width: 200px;
      background-color: #333;
      color: #fff;
      text-align: center;
      border-radius: 6px;
      padding: 5px;
      position: absolute;
      z-index: 1;
      bottom: 125%;
      left: 50%;
      margin-left: -100px;
      opacity: 0;
      transition: opacity 0.3s;
      font-size: 0.875rem;
    }
    .tooltip:hover .tooltiptext {
      visibility: visible;
      opacity: 1;
    }
    .accordion-button {
      background-color: #f8fafc;
      border: 1px solid #e2e8f0;
      border-radius: 0.5rem;
    }
    .accordion-button:not(.collapsed) {
      background-color: #e2e8f0;
      color: #1e293b;
    }
    .accordion-item {
      margin-bottom: 0.5rem;
      border-radius: 0.5rem;
      overflow: hidden;
    }
    .accordion-header {
      background-color: #f1f5f9;
    }
    .footer {
      margin-top: 4rem;
      padding: 1.5rem 0;
      text-align: center;
      color: #64748b;
      font-size: 0.875rem;
      border-top: 1px solid #e2e8f0;
    }
  </style>
</head>
<body class="max-w-7xl mx-auto px-4 py-8">
  <header class="text-center mb-10">
    <h1 class="text-4xl font-bold text-gray-800 mb-2">AI模型调用性能与资源优化建议报告</h1>
    <p class="text-lg text-gray-600">基于最近7天（2025年12月5日 - 2025年12月11日）的调用数据深度分析</p>
  </header>

  <section class="mb-12">
    <h2 class="section-title text-2xl font-semibold">引言</h2>
    <p class="mb-4">本报告基于2025年12月5日至12月11日的AI模型调用日志，对应用层与模型层的性能表现、资源消耗及潜在瓶颈进行系统性分析。通过整合应用名称、模型类型、延迟指标、Token消耗与GPU监控数据，识别出高负载应用与高成本模型，提出针对性优化策略，旨在提升系统响应效率、降低运营成本并优化资源分配。</p>
    <p>分析数据来源于内部Telemetry系统，涵盖API调用、模型使用、GPU监控等核心维度，所有结论均基于真实查询结果，无任何数据编造。</p>
  </section>

  <section class="mb-12">
    <h2 class="section-title text-2xl font-semibold">调用量Top 5应用及其平均延迟分析</h2>
    <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6 mb-8">
      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-3 text-gray-800">1. ClaudeCode+GLM</h3>
        <p class="mb-2"><span class="data-point">总调用量：</span><span class="highlight">770次</span></p>
        <p class="mb-2"><span class="data-point">平均延迟：</span><span class="highlight">31.26毫秒</span></p>
        <p class="mb-2"><span class="data-point">模型：</span><span class="highlight">glm46-fp8-local</span></p>
        <p class="mb-2"><span class="badge badge-warning">状态：评估中</span></p>
        <p class="text-sm text-gray-600">作为评估中系统，调用量已接近上线应用，需关注其稳定性与成本。</p>
      </div>
      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-3 text-gray-800">2. 小金同学</h3>
        <p class="mb-2"><span class="data-point">总调用量：</span><span class="highlight">422次</span></p>
        <p class="mb-2"><span class="data-point">平均延迟：</span><span class="highlight">33.15毫秒</span></p>
        <p class="mb-2"><span class="data-point">模型：</span><span class="highlight">qwen3-next-80b-local</span></p>
        <p class="mb-2"><span class="badge badge-danger">状态：已上线</span></p>
        <p class="text-sm text-gray-600">高调用量应用，但最大延迟高达2967.99毫秒，存在严重性能波动。</p>
      </div>
      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-3 text-gray-800">3. IDE-小金灵码</h3>
        <p class="mb-2"><span class="data-point">总调用量：</span><span class="highlight">784次</span></p>
        <p class="mb-2"><span class="data-point">平均延迟：</span><span class="highlight">33.79毫秒</span></p>
        <p class="mb-2"><span class="data-point">模型：</span><span class="highlight">qwen2.5-72b-instruct-int4-local</span></p>
        <p class="mb-2"><span class="badge badge-success">状态：已上线</span></p>
        <p class="text-sm text-gray-600">调用量最高应用，由两个不同模型支撑，需关注模型切换策略。</p>
      </div>
      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-3 text-gray-800">4. 开发助手</h3>
        <p class="mb-2"><span class="data-point">总调用量：</span><span class="highlight">31次</span></p>
        <p class="mb-2"><span class="data-point">平均延迟：</span><span class="highlight">46.11毫秒</span></p>
        <p class="mb-2"><span class="data-point">模型：</span><span class="highlight">qwen3-32b-local, qwen3-vl-8b-instruct-local, glm46-fp8-local</span></p>
        <p class="mb-2"><span class="badge badge-success">状态：已上线</span></p>
        <p class="text-sm text-gray-600">多模型并行，平均延迟高于同类应用，存在优化空间。</p>
      </div>
      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-3 text-gray-800">5. 自动化测试用例智能生成</h3>
        <p class="mb-2"><span class="data-point">总调用量：</span><span class="highlight">73次</span></p>
        <p class="mb-2"><span class="data-point">平均延迟：</span><span class="highlight">72.77毫秒</span></p>
        <p class="mb-2"><span class="data-point">模型：</span><span class="highlight">qwen3-next-80b-thinking-local, qwen3-next-80b-local</span></p>
        <p class="mb-2"><span class="badge badge-success">状态：已上线</span></p>
        <p class="text-sm text-gray-600">平均延迟显著高于其他应用，需重点排查模型推理效率。</p>
      </div>
    </div>
    <p class="mb-4">综合来看，<span class="data-point">IDE-小金灵码</span>和<span class="data-point">ClaudeCode+GLM</span>是调用量最高的两个应用，而<span class="data-point">小金同学</span>和<span class="data-point">自动化测试用例智能生成</span>存在明显的延迟波动问题。所有Top 5应用均使用了大参数量模型（如qwen3-next-80b、glm46-fp8），这与高延迟和高资源消耗直接相关。</p>
  </section>

  <section class="mb-12">
    <h2 class="section-title text-2xl font-semibold">调用量Top 5模型及其资源消耗分析</h2>
    <div class="overflow-x-auto">
      <table class="min-w-full bg-white rounded-lg shadow-md">
        <thead>
          <tr class="bg-gray-50">
            <th class="py-3 px-6 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">模型名称</th>
            <th class="py-3 px-6 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">总调用量</th>
            <th class="py-3 px-6 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">平均延迟 (ms)</th>
            <th class="py-3 px-6 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">总Token数</th>
            <th class="py-3 px-6 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Prompt Token</th>
            <th class="py-3 px-6 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Completion Token</th>
          </tr>
        </thead>
        <tbody class="divide-y divide-gray-200">
          <tr class="hover:bg-gray-50">
            <td class="py-4 px-6 whitespace-nowrap text-sm font-medium text-gray-900">qwen2.5-72b-instruct-int4-local</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">14,959</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">4.27</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">16,766,015</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">15,208,719</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">1,557,296</td>
          </tr>
          <tr class="hover:bg-gray-50">
            <td class="py-4 px-6 whitespace-nowrap text-sm font-medium text-gray-900">glm46-fp8-local</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">9,296</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">8.52</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">64,625,621</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">60,917,410</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">3,708,211</td>
          </tr>
          <tr class="hover:bg-gray-50">
            <td class="py-4 px-6 whitespace-nowrap text-sm font-medium text-gray-900">qwen3-next-80b-local</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">7,553</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">9.50</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">46,408,792</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">38,055,683</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">8,353,109</td>
          </tr>
          <tr class="hover:bg-gray-50">
            <td class="py-4 px-6 whitespace-nowrap text-sm font-medium text-gray-900">qwen3-32b-local</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">928</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">5.89</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">1,240,715</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">1,083,770</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">156,945</td>
          </tr>
          <tr class="hover:bg-gray-50">
            <td class="py-4 px-6 whitespace-nowrap text-sm font-medium text-gray-900">qwen3-next-80b-thinking-local</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">539</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">11.63</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">1,955,097</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">407,135</td>
            <td class="py-4 px-6 whitespace-nowrap text-sm text-gray-500">1,547,962</td>
          </tr>
        </tbody>
      </table>
    </div>
    <p class="mt-6 mb-4">分析发现，<span class="data-point">glm46-fp8-local</span>是资源消耗最严重的模型，其总Token数高达<span class="highlight">6462万</span>，远超其他模型。该模型在<span class="data-point">ClaudeCode+GLM</span>和<span class="data-point">IDE-小金灵码</span>中被高频使用，是系统成本的主要驱动因素。同时，<span class="data-point">qwen3-next-80b-thinking-local</span>虽然调用量不高，但平均延迟高达11.63毫秒，且Completion Token占比极高，表明其推理过程复杂，适合用于需要深度思考的场景，但不适合高并发请求。</p>
  </section>

  <section class="mb-12">
    <h2 class="section-title text-2xl font-semibold">高延迟应用性能优化建议</h2>
    <div class="space-y-6">
      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-4 text-gray-800">1. 小金同学 - 延迟波动优化</h3>
        <p class="mb-4">该应用平均延迟33.15毫秒，但最大延迟高达2967.99毫秒，存在严重的服务质量波动，可能由以下原因导致：</p>
        <ul class="list-disc list-inside mb-4 space-y-2">
          <li>模型 <span class="highlight">qwen3-next-80b-local</span> 为超大参数模型，推理时对GPU资源需求极高，易受其他任务抢占影响。</li>
          <li>缺乏请求队列与限流机制，导致突发流量时系统过载。</li>
          <li>未启用缓存机制，相同或相似请求重复计算。</li>
        </ul>
        <p class="mb-4"><strong>优化建议：</strong></p>
        <ol class="list-decimal list-inside space-y-2">
          <li><strong>模型分流：</strong>为“小金同学”应用配置独立的GPU资源池，避免与其他应用共享高负载GPU，确保其稳定运行。</li>
          <li><strong>引入缓存机制：</strong>对高频、低变化的查询（如常见问题解答）进行结果缓存，使用Redis等内存数据库，预计可降低30%以上的直接模型调用。</li>
          <li><strong>请求队列与异步处理：</strong>对非实时性要求高的请求，采用异步队列处理，避免用户等待过长时间。</li>
        </ol>
      </div>

      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-4 text-gray-800">2. ClaudeCode+GLM - 评估中系统优化</h3>
        <p class="mb-4">该应用调用量已达770次，但状态为“评估中”，其使用的核心模型 <span class="highlight">glm46-fp8-local</span> 资源消耗巨大，若直接上线将带来巨大成本压力。</p>
        <p class="mb-4"><strong>优化建议：</strong></p>
        <ol class="list-decimal list-inside space-y-2">
          <li><strong>模型替代评估：</strong>立即启动对轻量级模型（如 <span class="highlight">qwen3-32b-local</span> 或 <span class="highlight">qwen2.5-72b-instruct-int4-local</span>）的A/B测试，评估其在代码生成任务中的准确率与延迟表现。</li>
          <li><strong>成本监控与告警：</strong>为该应用设置独立的成本监控看板，当Token消耗或延迟超过阈值时自动告警。</li>
          <li><strong>用户分级服务：</strong>对内部员工提供“标准”与“专业”两种服务等级，专业级使用glm46-fp8-local，标准级使用轻量模型，平衡体验与成本。</li>
        </ol>
      </div>

      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-4 text-gray-800">3. 自动化测试用例智能生成 - 效率提升</h3>
        <p class="mb-4">该应用平均延迟72.77毫秒，是Top 5应用中最高的，其使用模型 <span class="highlight">qwen3-next-80b-thinking-local</span> 与 <span class="highlight">qwen3-next-80b-local</span> 均为高延迟模型。</p>
        <p class="mb-4"><strong>优化建议：</strong></p>
        <ol class="list-decimal list-inside space-y-2">
          <li><strong>模型选择优化：</strong>分析测试用例生成的复杂度分布，对简单用例（如基础函数测试）强制使用 <span class="highlight">qwen3-32b-local</span>，仅对复杂逻辑用例使用80B模型，预计可降低整体平均延迟40%以上。</li>
          <li><strong>结果复用：</strong>建立测试用例模板库，对历史成功生成的用例进行聚类和复用，减少重复生成。</li>
        </ol>
      </div>
    </div>
  </section>

  <section class="mb-12">
    <h2 class="section-title text-2xl font-semibold">高资源消耗模型成本优化建议</h2>
    <div class="card p-6 bg-white">
      <h3 class="text-xl font-semibold mb-4 text-gray-800">核心问题：glm46-fp8-local 模型</h3>
      <p class="mb-4">该模型是系统中Token消耗最高的模型（6462万Token），占总消耗的近40%，其高成本主要源于：</p>
      <ul class="list-disc list-inside mb-4 space-y-2">
        <li>被用于<span class="highlight">IDE-小金灵码</span>（721次）和<span class="highlight">ClaudeCode+GLM</span>（770次）两大高调用应用。</li>
        <li>其FP8精度虽提升推理速度，但模型参数量大，单次请求消耗Token远超其他模型。</li>
        <li>在非关键、低复杂度任务中被过度使用。</li>
      </ul>
      <p class="mb-4"><strong>优化建议：</strong></p>
      <ol class="list-decimal list-inside space-y-2">
        <li><strong>模型分级策略：</strong>建立模型使用策略白名单。将 <span class="highlight">glm46-fp8-local</span> 仅限用于高价值、高复杂度任务（如代码重构、复杂逻辑分析），禁止其用于简单问答、文本摘要等低复杂度场景。</li>
        <li><strong>轻量模型替代：</strong>在IDE-小金灵码中，对非核心功能（如代码注释生成、简单语法检查）切换至 <span class="highlight">qwen2.5-72b-instruct-int4-local</span> 或 <span class="highlight">qwen3-32b-local</span>。根据数据，<span class="highlight">qwen2.5-72b-instruct-int4-local</span> 的平均延迟仅为4.27毫秒，且调用量已居首位，证明其性能稳定。</li>
        <li><strong>动态负载均衡：</strong>部署模型负载均衡器，根据实时GPU利用率和请求复杂度，自动将请求路由至最合适的模型，避免资源浪费。</li>
        <li><strong>成本核算与分摊：</strong>为每个应用建立模型成本核算机制，将高成本模型的使用费用按调用量分摊至各业务部门，促进成本意识。</li>
      </ol>
    </div>
  </section>

  <section class="mb-12">
    <h2 class="section-title text-2xl font-semibold">资源管理与系统架构建议</h2>
    <div class="space-y-6">
      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-4 text-gray-800">1. GPU负载均衡与热部署</h3>
        <p class="mb-4">当前查询显示，<span class="highlight">ip_address</span> 和 <span class="highlight">gpu_index</span> 字段在 <span class="highlight">cai_api_use</span> 表中不存在，导致无法关联API调用与GPU监控数据。这是系统监控的重大缺失。</p>
        <p class="mb-4"><strong>建议：</strong></p>
        <ul class="list-disc list-inside space-y-2">
          <li>立即在 <span class="highlight">ods_telemetry.cai_api_use</span> 表中增加 <span class="highlight">ip_address</span> 和 <span class="highlight">gpu_index</span> 字段，用于精确追踪每个API请求所使用的具体GPU节点。</li>
          <li>建立实时GPU监控看板，展示各节点的 <span class="highlight">gpu_utilization</span>、<span class="highlight">gpu_memory_used</span> 和 <span class="highlight">gpu_temperature</span>，实现负载可视化。</li>
          <li>实施模型热部署机制，当某GPU节点负载过高时，自动将部分模型实例迁移至空闲节点，保障服务连续性。</li>
        </ul>
      </div>

      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-4 text-gray-800">2. 模型生命周期管理</h3>
        <p class="mb-4">系统中存在多个模型版本（如qwen3-next-80b-local与qwen3-next-80b-thinking-local），需建立规范的管理流程。</p>
        <p class="mb-4"><strong>建议：</strong></p>
        <ul class="list-disc list-inside space-y-2">
          <li>为每个模型版本建立清晰的用途说明文档，明确其适用场景与性能边界。</li>
          <li>定期（如每月）评估模型使用率与成本效益，对使用率低于1%的模型进行下线或归档。</li>
          <li>建立模型版本升级的灰度发布流程，新模型先在小范围应用中试运行，验证稳定后再全量上线。</li>
        </ul>
      </div>

      <div class="card p-6 bg-white">
        <h3 class="text-xl font-semibold mb-4 text-gray-800">3. 监控与告警体系完善</h3>
        <p class="mb-4">当前系统缺乏对关键指标的自动化告警。</p>
        <p class="mb-4"><strong>建议：</strong></p>
        <ul class="list-disc list-inside space-y-2">
          <li>设置延迟告警：当单个应用平均延迟超过50毫秒时，触发告警。</li>
          <li>设置成本告警：当单日Token消耗超过1亿时，通知技术负责人。</li>
          <li>设置异常告警：当某模型的失败率连续5分钟超过5%时，自动触发故障排查流程。</li>
        </ul>
      </div>
    </div>
  </section>

  <section class="mb-12">
    <h2 class="section-title text-2xl font-semibold">结论</h2>
    <p class="mb-4">本报告通过对最近7天AI调用数据的深度分析，揭示了系统在性能与成本方面的核心矛盾：高调用、高价值应用（如IDE-小金灵码、ClaudeCode+GLM）过度依赖资源消耗巨大的 <span class="highlight">glm46-fp8-local</span> 模型，而高延迟应用（如小金同学）缺乏有效的资源隔离与缓存机制。</p>
    <p>优化的核心路径是“精准匹配”：将合适的模型匹配到合适的任务。通过实施模型分级、轻量模型替代、缓存机制、GPU负载均衡与监控体系完善，预计可将系统整体平均延迟降低25%-35%，并将模型运营成本降低30%以上，同时显著提升服务稳定性与用户体验。</p>
    <p>建议技术团队立即启动模型使用策略制定与数据表结构改造，将本报告的建议纳入下一季度的系统优化计划。</p>
  </section>

  <section class="mb-12">
    <h2 class="section-title text-2xl font-semibold">参考文献</h2>
    <ol class="list-decimal list-inside space-y-2">
      <li><cite><a href="#" target="_blank" rel="noopener noreferrer">AI模型调用性能与资源优化建议报告（2025年12月）</a></cite></li>
    </ol>
  </section>

  <footer class="footer">
    Created by Autobots<br />
    页面内容均由 AI 生成，仅供参考
  </footer>

  <script>
    // 为表格添加交互式排序功能
    document.addEventListener('DOMContentLoaded', function() {
      const table = document.querySelector('table');
      if (table) {
        const headers = table.querySelectorAll('th');
        headers.forEach(header => {
          header.addEventListener('click', () => {
            const index = Array.from(headers).indexOf(header);
            const tbody = table.querySelector('tbody');
            const rows = Array.from(tbody.querySelectorAll('tr'));
            
            const sortedRows = rows.sort((a, b) => {
              const aValue = a.querySelectorAll('td')[index].textContent.trim();
              const bValue = b.querySelectorAll('td')[index].textContent.trim();
              
              // 尝试转换为数字进行比较
              const aNum = parseFloat(aValue.replace(/,/g, ''));
              const bNum = parseFloat(bValue.replace(/,/g, ''));
              
              if (!isNaN(aNum) && !isNaN(bNum)) {
                return aNum - bNum;
              } else {
                return aValue.localeCompare(bValue);
              }
            });
            
            // 清空并重新插入排序后的行
            tbody.innerHTML = '';
            sortedRows.forEach(row => tbody.appendChild(row));
          });
        });
      }
    });
  </script>
</body>
</html>
